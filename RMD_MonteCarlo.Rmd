---
title: "The_RMD_MonteCarlo"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)

library(readxl)

library(shiny)

library(broom)

library('rsconnect')
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
Synthetic_Data_Small_Coverage_10082021 <- read_excel("Synthetic Data Small - Coverage 10082021.xlsx")






outpatient <- read_excel("Synthetic Data Small - Facility Outpatient 10082021.xlsx")

coverage <- read_excel("Synthetic Data Small - Coverage 10082021.xlsx")


facility_inpatient <- read_excel("Synthetic Data Small - Facility Inpatient 10082021.xlsx")

member <- read_excel("Synthetic Data Small - Member 10082021.xlsx")

patient <- read_excel("Synthetic Data Small - Patient 10082021.xlsx")

pharmacy <- read_excel("Synthetic Data Small - Pharmacy 10082021.xlsx")

professional <- read_excel("Synthetic Data Small - Professional 10082021.xlsx")





Synthetic <- full_join(outpatient, coverage, facility_inpatient, member, by = "Member ID (secure)", suffix = c(".x", ".y"))



Synthetic <- full_join(outpatient, coverage, member, by = "Member ID (secure)")


half <- full_join(facility_inpatient, patient, pharmacy, professional, by = "Member ID (secure)", suffix = c(".x", ".y"))

half <- full_join(patient, pharmacy, professional, by = "Member ID (secure)")

inpatient <- read_excel("Synthetic Data Small - Facility Inpatient 10082021.xlsx")


full_synthetic <- full_join(half, Synthetic, inpatient, by = "Member ID (secure)", suffix = c(".x", ".y"))


```

So all of this above is what I like to call "the great join" where I downloaded all of the excel files into R, and then proceeded to join them together to bring all the data into one table.




```{r Now its time to get funky}

ICD_10_accuracy <- full_synthetic %>%
  select('Member ID (secure)', memb_brth_dt.x, memb_gender_cd.x, patient_name, state_nm, allwd_amt.x, princ_icd10_diag_cd, admtng_icd10_diag_cd)
  
view(ICD_10_accuracy)

```

We set up this table to test ICD 10 accuracy 
```{r function to check accurarcy}

# accuracy <- function(data_set, col_name1, col_name2)
#   {
#   
#   if((data_set$col_name1) == (data_set$col_name2)){
#     
#     mutate(data_set, Accurate = 1)
#   }
#   else{
#     mutate(data_set, Accurate = 0)
#   }
#   
#     
#   
#   
# }
# 
# accuracy(ICD_10_accuracy, princ_icd10_diag_cd, admtng_icd10_diag_cd)


ICD_10_accuracy %>%
  mutate(accurate = if_else(princ_icd10_diag_cd == admtng_icd10_diag_cd, 1, 0)) %>%
  filter(!is.na(accurate))


```

There were no cases where the admitting ICD10 and the diagnosis ICD10 where the same.  Either they had an NA or did not match.  Important to note because we can see the admitting diagnosis does not equal the original diagnosis.



```{r We get up and try again}

Amount_allowed <- full_synthetic %>%
  select(state_nm, allwd_amt.x, sbmtd_amt.x, copay_coin_amt, coin_amt, ded_amt)
  

Diag_amount_allowed <- full_synthetic %>%
  group_by(princ_icd10_diag_cd) %>%
  summarise(mean = mean(allwd_amt.x, na.rm = TRUE), sd = sd(allwd_amt.x, na.rm = TRUE), n = n())

```


This next part was attempting to do the Monte carlo to generate new data based on diagnosis and get new financial data.

```{r function time}


## I found that this produced a huge dataset that was unusable due to too many NA's.  Many entries in the diagnosis had nothing but NA's, we couldn't get an accurate picture of it with so many entries with NA's.  That, and some entries had only one value to return.

map2(Diag_amount_allowed$mean, Diag_amount_allowed$sd, ~rnorm(100, .x, .y))
```

From this, I will change gears and look for a way to find the most accurate deductible given the current data:

```{r Let's do some calculations}
allwd_amnt_tibble <- full_synthetic %>%
  summarise(mean = mean(allwd_amt.x, na.rm = TRUE), sd = sd(allwd_amt.x, na.rm = TRUE))

sbmtd_amnt_tibble <- full_synthetic %>%
  summarise(mean = mean(sbmtd_amt.x, na.rm = TRUE), sd = sd(sbmtd_amt.x, na.rm = TRUE))

copay_coin_amnt_tibble <- full_synthetic %>%
  summarise(mean = mean(copay_coin_amt, na.rm = TRUE), sd = sd(copay_coin_amt, na.rm = TRUE))

coin_amnt_tibble <- full_synthetic %>%
  summarise(mean = mean(coin_amt, na.rm = TRUE), sd = sd(coin_amt, na.rm = TRUE))

ded_amnt_tibble <- full_synthetic %>%
  summarise(mean = mean(ded_amt, na.rm = TRUE), sd = sd(coin_amt, na.rm = TRUE))


```

This is used to generate random samples of data as first creating normal distributions.  We do this to give the data some structure when generating the new samples.

```{r Simulation and what not}

Allwd_amnt_column <- rnorm(1000, mean = allwd_amnt_tibble$mean, sd = allwd_amnt_tibble$sd)
Sbmtd_amnt_column <- rnorm(1000, mean = sbmtd_amnt_tibble$mean, sd = allwd_amnt_tibble$sd)
Copay_coin_amnt_column <- rnorm(1000, mean = copay_coin_amnt_tibble$mean, sd = copay_coin_amnt_tibble$sd)
Coin_amnt_column <- rnorm(1000, mean = coin_amnt_tibble$mean, sd = coin_amnt_tibble$sd)
Ded_amnt_column <- rnorm(1000, mean = ded_amnt_tibble$mean, sd = ded_amnt_tibble$sd)

Linear_frame <- tibble(Allwd_amnt_column, Sbmtd_amnt_column, Copay_coin_amnt_column, Coin_amnt_column, Ded_amnt_column)

```

We are combining all of the new generated data into a single tibble for simplicity 

```{r Let's change gears and do MLM}

model_for_ded <- lm(Ded_amnt_column~Allwd_amnt_column+Sbmtd_amnt_column+Copay_coin_amnt_column+Coin_amnt_column, Linear_frame)

```

This is to make the actual linear model and running it on the random data

```{r Print the model to check}

summary(model_for_ded)

```

```{r Now we try to get a nested data frame}


Nested_amount_allowed2 <- Amount_allowed %>%
  group_by(state_nm) %>%
  nest()

```
Nesting the data to include State as policies and insurance amounts do differ from state to state.
```{r Now we get the formula to each state}

Nested_amount_allowed2 <- Nested_amount_allowed2 %>%
  mutate(model = map(data, ~lm(ded_amt~., data = .x)),
         fits = map(model, broom::tidy)) %>%
  unnest(fits)

```






```{r Testing out the application data}
Nested_amount_allowed2 %>%
      filter(state_nm  == "Arizona") %>%
      mutate(values = c(1, 500, 600, 400, 200), 
             multiply = estimate * values)%>%
      summarise(pred = sum(multiply)) %>%
  pull(pred)
  
```



```{r General formula for deducitble}

deductible <- function(allwd_amt, sbtd_amt, copay_coin_amt, coin_amt){
  
  deductible = 22.95425 + (allwd_amt * 804.88442) + (sbtd_amt * -784.75091) + (copay_coin_amt * -0.02612) + (coin_amt * 0.72997)
  
  return(deductible)
}

## This is meant as a standard deductible formula without taking state into consideration

```

```{r Testing it out}



deductible(5000, 2000, 200, 500)


```

```{r We are going to explore further into the Original dataset}

Location <- full_synthetic %>%
  select(memb_brth_dt.x, memb_gender_cd.x, memb_rltnshp_cd, patient_name, state_nm, county_nm, country, address, mbrs_crnt_prim_zip_cd, "Member ID (secure)")

```

We are exploring more data by location as we noted earlier the differences in policy depending on location.

```{r Seeing patient location}

Location %>%
  group_by(state_nm) %>%
  ggplot(aes(county_nm, fill = state_nm)) +
  geom_bar()



```
We can also see the majority of entries are from Illinois and the next being Texas.


I now have curiosity from Cook county claims.  Let's explore

```{r Error code}

## Location_Amount <- full_join(Amount_allowed, Location, BY = "Member ID (secure)")
## okay so, we ran into an issue here where I got "Error: cannot allocate vector of size 6.3 Gb" So we are gonna do a different approach...

```

```{r New way or the highway}
Location_amount <- full_synthetic %>%
  select(princ_icd10_diag_cd, "Member ID (secure)",  memb_brth_dt.x, memb_gender_cd.x, patient_name, state_nm, allwd_amt.x, sbmtd_amt.x, copay_coin_amt, coin_amt, ded_amt, state_nm, county_nm, country, address, mbrs_crnt_prim_zip_cd)
```

```{r Time for some numerical summaries}

Location_amount %>%
  group_by(princ_icd10_diag_cd) %>%
  filter(county_nm == "COOK") %>%
  summarise(n = n()) %>%
  arrange(desc(n))
#This shows us that in the county with the most claims, the most common diagnosis was N18.6.  This code is for end-stage renal disease.

```
```{r Exploring N18.6}

Location_amount %>%
  filter(princ_icd10_diag_cd == "N18.6")


```


In the end, we were able to gather more insight on this data and provide an application to better predict deductible amounts.  We were able to find out how location in state affected the financial variables and what diagnosis was the most common.  Overall, we made great use of this synthetic data and bring real meaning and value out of it.


