# How I have grown as a data person
Before this course, I had some minor experience with data analytics and working with data, I would describe it as very basic analysis and tasks.  Manipulating data in excel, making graphs, tables, etc.  Throughout this course, I have learned that I merely scratched the surface of what it means to work with data.  I learned there is a lot more to data analytics than just running numbers through a calculation or making a nice graph, it involves cleaning, manipulating, analyzing and presenting results in a way that is readable and understandable to a wider audience.  

The biggest ideas or practices I learned in this semester would be cleaning data and manipulation.  The process of clearing invalid entries, organzing the data into a way that makes sense like moving some observations into values or combining variables like dates.  I highlight these two things because cleaning data was something that I thought I knew how to do but just did very basic things like delete null entries or invalid entries, but it goes further than that like does this attribute fit more like an entry or row of data? Does this column need to be split into two different columns and how to do we do that cleanly and effectively? I always thought as someone who worked with data as someone who did complex analysis on a already nice and clean data set, but often times, these professionals have to clean it themselves and ‘wrangle’ it into a format that meets the need of their analysis or criteria.  

In my project I learned how important it is to clean data because when joined multiple tables together, it created a significant amount of null entries because the variables didn't overlap and thus the new data set needed to account for obserations not common in the other tables.  

Manipulation was an idea that I thought I knew how to do well because of my experience in Microsoft Excel, but that was very much 'spoon fed' manipulation in the way that you can do it with a lot of copy and paste and hiding columns.  This project was my first real introduction about having to specify what columns I want, what calculations I need to run on what column for a new observation and utilizing group by, or filter functions to organize into a common traits.  This was the most rewarding skill to learn as I struggled at first, but eventually found my stride within my own dataset since it was observations and variables I immersed myself in and became comfortable with. 

# Lightning Round
- I would describe the most difficult part of the class as the pivoting section from week 4.  That part was the most complicated for me because the idea or practice of transferring variables or keys was a hard thing to process because it required some foresight into how it would look once the operation was done, and trial and error.
- The easiest part of the class was user created functions from my experience.  I saw this because I was also learning user created functions in my python course at the same time and had a double dose of this idea.  The idea itself is straighforward, you ask for certain variables and then process give a result from those variables at the end.  Almost like running it through a machine.  You have a variable, you know what the machine does, you want the change the machine will bring to apply to your variable, and so you run it through the machine and get the desired change or result.
- The part of class that interested me the most was bootstrapping and simulation.  I always had a love for statistics and probability, it was a welcomed surprise when I saw this as a lesson we would focus on.  This should a strong functionality of R that other data driven softwares either lack or can't meet the level that R offers.
- I would say a piece of advice that I would offer someone just starting this course would be to think of ways you can apply the current lesson in your job, your project or find examples on why this lesson is important to learn.  The next thing I would encourage to do, is do the primers before class.  I say this because it does make a difference typing code vs reading code.  This will help you learn and practice the lesson.  

# Grade Reflection
**Put simply enough, I believe I have earned an A for this class.**
I will reference the STA 418/518 course objectives to provide fulfilling evidence that I have met each objective and have met the requirements for an 'A' in this class.  
## Import, manage, and clean data
I have demonstrated this objective as seen in my R markdown file where I uploaded all the excel files from my company into R and then proceeded to combine them into one fully funcitoning table.  I went beyond and created specialized tables to fulfill requirements for getting the linear model, and display views based on state for the number of claims.  Both of these tasks involved isolating information from the larger combined data set and modifying it into a format suitable for this task.  I have created new tables based on normal distribution of existing information and combined these results to run my linear model upon.
## Create graphical displays and numerical summaries of data for exploratory analysis and presentations
I have demonstrated this objective by creating numerical summaries for the numerical factors in the linear model by finding the mean and standard deviation of these factors in an individual tibble and then running the simulation for random numbers and combining the results into one table of information.  This shows that I am able to create a regression model into a summary for exploratory analysis and for descriptive analysis.  I provided a summary for the original model before running it on the nested data to give information on the model to show p-value, estimate and standard error.  I also provided information on the estimate, p value, and term for the individual state in one summary.  A graphical display was provided to see the distribution of claims across the states that would be used for presentation to provide comaprison for the nested data. 





